# ğŸ‘‹ Hello

Bridging the Reality Gap: Sim-to-Real & Embodied AI Researcher
"My goal is to implement VLA and Reinforcement Learning in the physical world, bringing robust, intelligent robots from simulation into our daily lives."

ğŸš€ Focused on: Sim-to-Real Transfer | VLA Models | Robot Learning

## ğŸ›  Skills
- **Languages:** [Python, C++, etc.]
- **Frameworks/Libraries:** [ROS2, Omniverse Isaac Sim, etc.]
- **Tools:** [Git, etc.]

## ğŸš€ Projects
### 1. ğŸ¤– DolbotX (ë‹¤ëª©ì  ì„ë¬´ ìˆ˜í–‰ ë¡œë´‡ / Multi-purpose Mission Robot)
- **Description:** 
  - ğŸ‡°ğŸ‡· í—˜ì§€ ê·¹ë³µ, ë¬¼ì²´ ì¶”ì , ë¹„ì „ ì¸ì‹ ë° ë¡œë´‡íŒ” í”¼í‚¹ ê¸°ëŠ¥ì„ ê°–ì¶˜ ROS2 ê¸°ë°˜ì˜ ë‹¤ëª©ì  ììœ¨ ì£¼í–‰ ë¡œë´‡ ê°œë°œ
  - ğŸ‡¬ğŸ‡§ Developed a ROS2-based multi-purpose autonomous robot capable of overcoming rough terrain, object tracking, vision recognition, and robotic arm picking.
- **Roles & Features:**
  - ğŸ‡°ğŸ‡· í—˜ì§€ í™˜ê²½ì—ì„œì˜ ì£¼í–‰ ì œì–´ ë° ê·¹ë³µ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
  - ğŸ‡¬ğŸ‡§ Implemented driving control and overcoming algorithms in rough terrain environments.
  - ğŸ‡°ğŸ‡· ë¹„ì „ ì¸ì‹ ê¸°ë°˜ì˜ ë¬¼ì²´ íƒì§€ ë° ì‹¤ì‹œê°„ íƒ€ê²Ÿ ì¶”ì 
  - ğŸ‡¬ğŸ‡§ Real-time target tracking and object detection based on vision recognition.
  - ğŸ‡°ğŸ‡· íŒŒì•… ëŒ€ìƒ ì¸ì§€ í›„ ë¡œë´‡íŒ”ì„ ì´ìš©í•œ ì •ë°€ í”¼í‚¹ ì‘ì—… ìˆ˜í–‰
  - ğŸ‡¬ğŸ‡§ Precise picking operation using a robotic arm after recognizing the target object.
- **Tech Stack:** 
  - `ROS2` `Python` `C++` `Moveit 2` `MTC` (Software)
  - `NVIDIA Jetson` `Arduino` `OpenCR` (Hardware & Embedded)
- **Link:** [GitHub ë ˆí¬ì§€í† ë¦¬ ë§í¬ - ì¶”ê°€ í•„ìš”]

### 2. ğŸ¦½ ìŒì„± ì œì–´ ì „ë™ íœ ì²´ì–´ ì‹œìŠ¤í…œ (Voice-Controlled Autonomous Wheelchair)
- **Description:** 
  - ğŸ‡°ğŸ‡· ì „ì‹ ë§ˆë¹„ ì¥ì• ì¸ì˜ ììœ¨ì ì¸ ì´ë™ì„ ì§€ì›í•˜ëŠ” ROS 2 ê¸°ë°˜ ìŒì„± ì œì–´ ì „ë™íœ ì²´ì–´ ì‹œìŠ¤í…œ ê°œë°œ
  - ğŸ‡¬ğŸ‡§ Developed a ROS 2-based voice-controlled autonomous wheelchair system to support the autonomous mobility of paralyzed individuals.
- **Roles & Features:**
  - ğŸ‡°ğŸ‡· STT -> LLM -> Nav2 -> Actionìœ¼ë¡œ ì´ì–´ì§€ëŠ” íŒŒì´í”„ë¼ì¸ í†µí•© ì œì–´ ì²´ê³„ êµ¬ì¶•
  - ğŸ‡¬ğŸ‡§ Built an integrated control pipeline connecting STT, LLM, Nav2, and Action.
  - ğŸ‡°ğŸ‡· Depth ì¹´ë©”ë¼, 2D LiDAR, IMU ì„¼ì„œ ë°ì´í„°ë¥¼ ìœµí•©í•˜ì—¬ í™˜ê²½ ì¸ì§€ ë° ë¡œë´‡ ìœ„ì¹˜ ì¶”ì •
  - ğŸ‡¬ğŸ‡§ Environmental perception and robot localization by fusing Depth camera, 2D LiDAR, and IMU sensor data.
  - ğŸ‡°ğŸ‡· SLAM ë° Localization ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì•ˆì •ì ì¸ ì‹¤ë‚´ ììœ¨ ì£¼í–‰ êµ¬í˜„
  - ğŸ‡¬ğŸ‡§ Implemented stable indoor autonomous driving using SLAM and localization technologies.
- **Tech Stack:** 
  - `ROS 2` `Python` `Nav2` `SLAM`
  - `STT` `LLM`
  - `Depth Camera` `2D LiDAR` `IMU`
  - `Hardware Design`
- **Link:** [GitHub ë ˆí¬ì§€í† ë¦¬ ë§í¬ - ì¶”ê°€ í•„ìš”]

### 3. ğŸ¤– SmolVLA ê¸°ë°˜ ë¡œë´‡ íŒ” ì œì–´ ë° ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ (SmolVLA-Gazebo Integration Pipeline)
- **Description:** 
  - ğŸ‡°ğŸ‡· ìµœì‹  Vision-Language-Action (SmolVLA) ëª¨ë¸ì„ ì»¤ìŠ¤í…€ ë¡œë´‡ íŒ”ì— ì ìš©í•˜ê¸° ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶•
  - ğŸ‡¬ğŸ‡§ Built a simulation-based training and testing environment to integrate a state-of-the-art VLA model (SmolVLA) with a custom robotic arm.
- **Roles & Features:**
  - ğŸ‡°ğŸ‡· [Data Generation] MoveItê³¼ RViz ì¸í„°í˜ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ë¡œë´‡ íŒ”ì˜ ì‹œê°-í–‰ë™(Vision-Action) ê¶¤ì  ë°ì´í„°ë¥¼ ì§ì ‘ ìƒì„±í•˜ê³  í•™ìŠµìš© ë°ì´í„°ì…‹ êµ¬ì¶•
  - ğŸ‡¬ğŸ‡§ Generated vision-action trajectory data and built a custom training dataset utilizing MoveIt and the RViz interface.
  - ğŸ‡°ğŸ‡· [Pipeline Setup] SmolVLA ëª¨ë¸ê³¼ Gazebo ì‹œë®¬ë ˆì´í„°ë¥¼ ì—°ë™í•˜ì—¬ ì´ë¯¸ì§€ ë°ì´í„° ìˆ˜ì§‘ ë° ì•¡ì…˜ ëª…ë ¹ì„ ì£¼ê³ ë°›ëŠ” ì „ì²´ ì¶”ë¡  ë£¨í”„(Inference Loop) ì„¤ê³„
  - ğŸ‡¬ğŸ‡§ Designed an end-to-end inference loop connecting the SmolVLA model with Gazebo to stream image data and execute action commands.
  - ğŸ‡°ğŸ‡· [Task Adaptation] ë¬¼ë¦¬ ì—”ì§„ì˜ ì ‘ì´‰(Contact) ì‹œë®¬ë ˆì´ì…˜ ë¶ˆì•ˆì •ì„±ì„ ê³ ë ¤í•˜ì—¬, íŒŒì§€(Grasping) ëŒ€ì‹  ë¬¼ì²´ ì§‘ê¸° ì§ì „ê¹Œì§€ì˜ 'ëª©í‘œ ê°ì²´ ë„ë‹¬(Pre-grasp Reaching)' ëª¨ì…˜ìœ¼ë¡œ íƒœìŠ¤í¬ë¥¼ ì¬ì •ì˜í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦
  - ğŸ‡¬ğŸ‡§ Redefined the task to 'pre-grasp reaching' to validate the model's spatial reasoning, deliberately avoiding the simulator's unstable contact dynamics during full grasping.
- **Troubleshooting & Future Work:**
  - ğŸ‡°ğŸ‡· í˜„ì¬ íŒŒì´í”„ë¼ì¸ ìƒì˜ ì¶”ë¡  ì˜¤ì°¨(ì´ë¯¸ì§€ ì „ì†¡ ì†ì‹¤, í•™ìŠµ ë°ì´í„°ì…‹ í¸í–¥ì„± ë“±) ì›ì¸ ë¶„ì„ ë° ëª¨ë¸ ìµœì í™” ë°©í–¥ ëª¨ìƒ‰
  - ğŸ‡¬ğŸ‡§ Analyzing inference errors (e.g., image transmission loss, training data bias) to optimize the model and improve the success rate of the reaching task.
- **Tech Stack:** 
  - `SmolVLA` `ROS 2` `Gazebo` `MoveIt` `RViz` `Python`
- **Link:** [GitHub ë ˆí¬ì§€í† ë¦¬ ë§í¬ - ì¶”ê°€ í•„ìš”]

### 4. ğŸ¦¾ ë¡œë´‡ íŒ” ê¸°ë°˜ ì£¼ì¡°í’ˆ ë””ë²„ë§ ìë™í™” íŒŒì´í”„ë¼ì¸ (Automated Robotic Deburring Pipeline)
- **Description:** 
  - ğŸ‡°ğŸ‡· Vision AIì™€ ì‹œë®¬ë ˆì´ì…˜ í•©ì„± ë°ì´í„°ë¥¼ í™œìš©í•œ 6ì¶• ë¡œë´‡ íŒ” ë””ë²„ë§(Deburring) ìë™í™” ë° í†µí•© ì œì–´ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• 
  - ğŸ‡¬ğŸ‡§ Built an automated 6-axis robotic deburring and integrated control pipeline utilizing Vision AI and simulation-based synthetic data.
- **Roles & Features:**
  - ğŸ‡°ğŸ‡· [Synthetic Data Generation] Isaac Simì„ í™œìš©í•˜ì—¬ ì •ìƒ ì£¼ì¡°í’ˆ 3D ëª¨ë¸ì— ë¬´ì‘ìœ„ ë²„(Burr)ë¥¼ ìƒì„±í•˜ê³ , 2D ì¹´ë©”ë¼ ë Œë”ë§ì„ í†µí•´ Vision ëª¨ë¸ í•™ìŠµìš© ëŒ€ê·œëª¨ í•©ì„± ë°ì´í„° êµ¬ì¶•
  - ğŸ‡¬ğŸ‡§ Generated large-scale synthetic data for Vision AI training by simulating randomized burrs on normal casted parts and rendering 2D camera images within Isaac Sim.
  - ğŸ‡°ğŸ‡· [Vision AI & Perception] êµ¬ì¶•í•œ í•©ì„± ë°ì´í„°ë¡œ IS-Netì„ í•™ìŠµì‹œì¼œ ì£¼ì¡°í’ˆì˜ ë²„ ê²½ê³„ë¥¼ ì •ë°€í•˜ê²Œ ì¶”ì¶œí•˜ê³  í¬ê¸°ë¥¼ ë¶„ì„ (OpenCV ì—°ë™)
  - ğŸ‡¬ğŸ‡§ Trained IS-Net with the synthetic dataset to accurately extract burr boundaries and analyze their sizes, integrated with OpenCV.
  - ğŸ‡°ğŸ‡· [Adaptive Path Planning] MoveIt 2ë¥¼ í™œìš©í•˜ì—¬ ë””ë²„ë§ ì›¨ì´í¬ì¸íŠ¸(Waypoint)ë¥¼ ìƒì„±í•˜ê³ , ì¸ì‹ëœ ë²„ì˜ í¬ê¸°ì— ë¹„ë¡€í•˜ì—¬ ë¡œë´‡ íŒ”ì˜ ê¶¤ì  ì´ë™ ì†ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” ê°€ë³€ ì†ë„ ì œì–´(Variable Speed Control) ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
  - ğŸ‡¬ğŸ‡§ Developed a variable speed control algorithm and generated waypoints using MoveIt 2, dynamically adjusting the robot arm's trajectory speed based on the analyzed burr size.
  - ğŸ‡°ğŸ‡· [Sim-to-Real Validation] ì‹¤ì œ ê°€ê³µ(Real Machining) ì „ ë‹¨ê³„ë¡œì„œ, Isaac Sim í™˜ê²½ ë‚´ì—ì„œ ë¡œë´‡ íŒ”ì˜ ì›¨ì´í¬ì¸íŠ¸ ì¶”ì¢… ë° ë””ë²„ë§ ê¶¤ì  ê²€ì¦ ìˆ˜í–‰
  - ğŸ‡¬ğŸ‡§ Validated the waypoint tracking and deburring trajectories within the Isaac Sim environment as a crucial pre-requisite for real-world physical machining.
- **Current Status & Future Work:**
  - ğŸ‡°ğŸ‡· ì¸ì§€(IS-Net)ë¶€í„° ì œì–´(MoveIt 2), ê²€ì¦(Isaac Sim)ê¹Œì§€ ì´ì–´ì§€ëŠ” ê°œë³„ ëª¨ë“ˆì˜ Sim-to-Real í†µí•© íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë° ìµœì í™” ì§„í–‰ ì¤‘
  - ğŸ‡¬ğŸ‡§ Currently integrating and optimizing the end-to-end Sim-to-Real pipeline, connecting perception (IS-Net), control (MoveIt 2), and simulation validation (Isaac Sim).
- **Tech Stack:** 
  - `ROS 2` `MoveIt 2` `Isaac Sim` `IS-Net` `OpenCV` `Python`
- **Link:** [GitHub ë ˆí¬ì§€í† ë¦¬ ë§í¬ - ì¶”ê°€ í•„ìš”]

## ğŸ“« Contact Me
- **Email:** [ì´ë©”ì¼ ì£¼ì†Œ]
- **Blog / Portfolio:** [ë¸”ë¡œê·¸ë‚˜ í¬íŠ¸í´ë¦¬ì˜¤ ì£¼ì†Œ]
