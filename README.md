# ğŸ‘‹ Hello

Bridging the Reality Gap: Sim-to-Real & Embodied AI Researcher
"My goal is to implement VLA and Reinforcement Learning in the physical world, bringing robust, intelligent robots from simulation into our daily lives."

ğŸš€ Focused on: Sim-to-Real Transfer | VLA Models | Robot Learning

## ğŸ›  Skills
- **Languages:** [Python, C++, etc.]
- **Frameworks/Libraries:** [ROS2, Omniverse Isaac Sim, etc.]
- **Tools:** [Git, etc.]

## ğŸš€ Projects
### 1. ğŸ¤– DolbotX (ë‹¤ëª©ì  ì„ë¬´ ìˆ˜í–‰ ë¡œë´‡ / Multi-purpose Mission Robot)
- **Description:** 
  - ğŸ‡°ğŸ‡· í—˜ì§€ ê·¹ë³µ, ë¬¼ì²´ ì¶”ì , ë¹„ì „ ì¸ì‹ ë° ë¡œë´‡íŒ” í”¼í‚¹ ê¸°ëŠ¥ì„ ê°–ì¶˜ ROS2 ê¸°ë°˜ì˜ ë‹¤ëª©ì  ììœ¨ ì£¼í–‰ ë¡œë´‡ ê°œë°œ
  - ğŸ‡¬ğŸ‡§ Developed a ROS2-based multi-purpose autonomous robot capable of overcoming rough terrain, object tracking, vision recognition, and robotic arm picking.
- **Roles & Features:**
  - ğŸ‡°ğŸ‡· í—˜ì§€ í™˜ê²½ì—ì„œì˜ ì£¼í–‰ ì œì–´ ë° ê·¹ë³µ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
  - ğŸ‡¬ğŸ‡§ Implemented driving control and overcoming algorithms in rough terrain environments.
  - ğŸ‡°ğŸ‡· ë¹„ì „ ì¸ì‹ ê¸°ë°˜ì˜ ë¬¼ì²´ íƒì§€ ë° ì‹¤ì‹œê°„ íƒ€ê²Ÿ ì¶”ì 
  - ğŸ‡¬ğŸ‡§ Real-time target tracking and object detection based on vision recognition.
  - ğŸ‡°ğŸ‡· íŒŒì•… ëŒ€ìƒ ì¸ì§€ í›„ ë¡œë´‡íŒ”ì„ ì´ìš©í•œ ì •ë°€ í”¼í‚¹ ì‘ì—… ìˆ˜í–‰
  - ğŸ‡¬ğŸ‡§ Precise picking operation using a robotic arm after recognizing the target object.
- **Tech Stack:** 
  - `ROS2` `Python` `C++` (Software)
  - `NVIDIA Jetson` `Arduino` `OpenCR` (Hardware & Embedded)
- **Link:** [GitHub ë ˆí¬ì§€í† ë¦¬ ë§í¬ - ì¶”ê°€ í•„ìš”]

### 2. ğŸ¦½ ìŒì„± ì œì–´ ì „ë™ íœ ì²´ì–´ ì‹œìŠ¤í…œ (Voice-Controlled Autonomous Wheelchair)
- **Description:** 
  - ğŸ‡°ğŸ‡· ì „ì‹ ë§ˆë¹„ ì¥ì• ì¸ì˜ ììœ¨ì ì¸ ì´ë™ì„ ì§€ì›í•˜ëŠ” ROS 2 ê¸°ë°˜ ìŒì„± ì œì–´ ì „ë™íœ ì²´ì–´ ì‹œìŠ¤í…œ ê°œë°œ
  - ğŸ‡¬ğŸ‡§ Developed a ROS 2-based voice-controlled autonomous wheelchair system to support the autonomous mobility of paralyzed individuals.
- **Roles & Features:**
  - ğŸ‡°ğŸ‡· STT -> LLM -> Nav2 -> Actionìœ¼ë¡œ ì´ì–´ì§€ëŠ” íŒŒì´í”„ë¼ì¸ í†µí•© ì œì–´ ì²´ê³„ êµ¬ì¶•
  - ğŸ‡¬ğŸ‡§ Built an integrated control pipeline connecting STT, LLM, Nav2, and Action.
  - ğŸ‡°ğŸ‡· Depth ì¹´ë©”ë¼, 2D LiDAR, IMU ì„¼ì„œ ë°ì´í„°ë¥¼ ìœµí•©í•˜ì—¬ í™˜ê²½ ì¸ì§€ ë° ë¡œë´‡ ìœ„ì¹˜ ì¶”ì •
  - ğŸ‡¬ğŸ‡§ Environmental perception and robot localization by fusing Depth camera, 2D LiDAR, and IMU sensor data.
  - ğŸ‡°ğŸ‡· SLAM ë° Localization ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì•ˆì •ì ì¸ ì‹¤ë‚´ ììœ¨ ì£¼í–‰ êµ¬í˜„
  - ğŸ‡¬ğŸ‡§ Implemented stable indoor autonomous driving using SLAM and localization technologies.
- **Tech Stack:** 
  - `ROS 2` `Python` `Nav2` `SLAM`
  - `STT` `LLM`
  - `Depth Camera` `2D LiDAR` `IMU`
  - `Hardware Design`
- **Link:** [GitHub ë ˆí¬ì§€í† ë¦¬ ë§í¬ - ì¶”ê°€ í•„ìš”]

## ğŸ“« Contact Me
- **Email:** [ì´ë©”ì¼ ì£¼ì†Œ]
- **Blog / Portfolio:** [ë¸”ë¡œê·¸ë‚˜ í¬íŠ¸í´ë¦¬ì˜¤ ì£¼ì†Œ]
